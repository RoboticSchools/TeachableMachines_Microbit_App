<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Teachable Machines + AI Vision Micro:bit</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
:root{
  --bg:#0f1115;
  --card:#14161a;
  --accent:#00c3ff;
  --good:#00ff99;
  --warn:#ffcc66;
  --error:#ff6b6b;
  --muted:#9fdfff;
  --panel-radius:14px;
  --gap:18px;
  --pad:18px;
  --left-width:300px;
  --right-width:360px;
  --max-width:1400px;
}
video#video{
  width:100%;
  max-width:920px;
  height:520px;
  border-radius:14px;
  background:#000;
  object-fit:cover;
  display:block;
  box-shadow:0 6px 18px rgba(0,0,0,0.6);
  transform:scaleX(-1);
}
html,body{height:100%;margin:0;background:var(--bg);color:#fff;font-family:Inter,Segoe UI,Arial,sans-serif;display:flex;align-items:flex-start;justify-content:center;padding:28px;}
.page { width:100%; max-width:var(--max-width); display:flex; flex-direction:column; gap:18px; align-items:center; }
.top-header { position: fixed; top: 28px; left: 28px; z-index:100; display:flex; align-items:center; gap:10px; }
.logo { height:44px; width:auto; cursor:pointer; transition:transform .18s ease; }
.logo:hover{ transform:scale(1.04); }
h1{font-weight:600;margin:6px 0 0 0;text-align:center}
.top-controls{ width:100%; display:flex; flex-direction:column; gap:12px; align-items:center; }
.controls-row{ width:100%; display:flex; gap:10px; align-items:center; justify-content:center; flex-wrap:wrap; }
.model-row{ display:flex; gap:10px; align-items:center; justify-content:center; }
.model-row input[type="text"]{ width:420px; max-width:760px; padding:12px 14px; border-radius:12px; border:0; background:#0b0c0e; color:#fff; box-shadow:inset 0 1px 0 rgba(255,255,255,0.02); font-size:15px; }
.model-row button{ padding:10px 18px; border-radius:10px; border:0; background:var(--accent); color:#002; font-weight:700; cursor:pointer; box-shadow:0 6px 18px rgba(0,195,255,0.06); }

.mid-buttons{ display:flex; gap:14px; align-items:center; justify-content:center; margin-top:0; }
.mid-buttons button{ padding:12px 22px; border-radius:12px; border:0; background:#1b1e25; color:#fff; cursor:pointer; font-weight:600; box-shadow:0 6px 18px rgba(0,0,0,0.4); }

.status-bar{ width:100%; max-width:980px; display:flex; justify-content:center; margin-top:6px; }
.status{ width:100%; max-width:820px; background:var(--card); padding:10px 14px; border-radius:12px; text-align:center; color:var(--muted); font-weight:600; box-shadow:0 6px 20px rgba(0,0,0,0.45); }

.content{ width:100%; display:grid; grid-template-columns: var(--left-width) 1fr var(--right-width); gap:24px; align-items:start; margin-top:6px; }
.classes-panel{ background:var(--card); border-radius:14px; padding:14px; box-shadow:0 12px 30px rgba(0,0,0,0.5); max-height:640px; display:flex; flex-direction:column; gap:12px; overflow:hidden; }
.classes-panel h3{ margin:0; font-size:15px; font-weight:800; color:var(--muted); display:flex; justify-content:space-between; align-items:center; }
.classes-list{ display:flex; flex-direction:column; gap:8px; overflow:auto; padding-right:6px; margin-top:6px; }
.class-row{ display:flex; justify-content:space-between; align-items:center; padding:10px 12px; border-radius:10px; background:rgba(255,255,255,0.015); font-weight:600; }
.class-name{ overflow:hidden; text-overflow:ellipsis; white-space:nowrap; max-width:180px; }
.class-pct{ min-width:48px; text-align:right; color:var(--muted); font-weight:700; }

.video-card{ background:linear-gradient(180deg,#0b0c0e,#0f1115); padding:14px; border-radius:18px; box-shadow:0 12px 40px rgba(0,0,0,0.6); display:flex; flex-direction:column; align-items:center; gap:12px; }
video#video{ width:100%; max-width:720px; height:420px; border-radius:14px; background:#000; object-fit:cover; display:block; box-shadow:0 6px 18px rgba(0,0,0,0.6); transform:scaleX(-1); }

.right-col{ display:flex; flex-direction:column; gap:14px; align-items:stretch; }
.card{ background:var(--card); border-radius:12px; padding:12px; box-shadow:0 8px 30px rgba(0,0,0,0.45); }
.slider-row{ display:flex; align-items:center; gap:10px; }
input[type="range"]{ width:100%; accent-color:var(--accent); margin:0; }
.percent{ min-width:46px; text-align:right; font-weight:700; color:var(--muted); }

#mainLabel{ font-size:20px; font-weight:800; text-align:center; padding:18px 12px; border-radius:10px; background:rgba(255,255,255,0.02); color:#fff; min-height:56px; display:flex; align-items:center; justify-content:center; }
.deviceName{ font-size:13px; color:#bfefff; margin-top:6px; text-align:center; }

@media (max-width:1100px){
  .content{ grid-template-columns: 260px 1fr 360px; gap:18px; }
  video#video{ height:360px; }
}
@media (max-width:860px){
  .content{ grid-template-columns: 1fr; }
  .classes-panel{ order: -1; width:100%; }
  .video-card{ width:100%; }
  .right-col{ width:100%; }
  video#video{ height:320px; max-width:100%; }
}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
</head>
<body>
  <header class="top-header">
    <img src="logo.png" alt="Robotic Schools Logo" class="logo">
  </header>

  <div class="page">
    <h1>Teachable Machines + AI Vision Micro:bit</h1>

    <div class="top-controls">
      <div class="controls-row">
        <div class="model-row">
          <input id="modelUrl" type="text" placeholder="Paste the Model URL ..." />
          <button id="loadBtn">Load Model</button>
        </div>

        <div class="mid-buttons">
          <button id="connectBtn">connect micro:bit</button>
        </div>
      </div>

      <div class="status-bar">
        <div id="status" class="status">status label</div>
      </div>

      <!-- Removed visible Normalization & Smoothing controls per request.
           Normalization and smoothing are now chosen automatically. -->

    </div>

    <div class="content">
      <div class="classes-panel">
        <h3>Classes <span id="classCount" style="font-weight:700;color:var(--muted)">—</span></h3>
        <div class="classes-list" id="classes"></div>
      </div>

      <div class="video-card">
        <video id="video" autoplay playsinline muted></video>
      </div>

      <div class="right-col">
        <div class="card">
          <div style="display:flex;justify-content:space-between;align-items:center">
            <div style="font-weight:700">Threshold</div>
          </div>
          <div style="height:10px"></div>
          <div class="slider-row">
            <input id="thresh" type="range" min="30" max="95" value="65" />
            <div class="percent" id="threshPct">65%</div>
          </div>
        </div>

        <div class="card" id="mainCard">
          <div id="mainLabel">—</div>
        </div>

        <div class="card" style="padding:10px;">
          <div style="font-weight:700;margin-bottom:8px">Device</div>
          <div class="deviceName" id="deviceName">—</div>
        </div>
      </div>
    </div>
  </div>

<script>
/* elements */
const video = document.getElementById('video');
const loadBtn = document.getElementById('loadBtn');
const connectBtn = document.getElementById('connectBtn');
const statusEl = document.getElementById('status');
const modelUrlInput = document.getElementById('modelUrl');
const mainLabelEl = document.getElementById('mainLabel');
const threshRange = document.getElementById('thresh');
const threshPct = document.getElementById('threshPct');
const classesEl = document.getElementById('classes');
const classCountEl = document.getElementById('classCount');
const deviceNameEl = document.getElementById('deviceName');

const STABLE_FRAMES_REQUIRED = 8;
const COOLDOWN_MS = 700;

let model = null;
let labels = [];
let inputWidth = 224, inputHeight = 224;
let stream = null;
let running = false;

let candidateIdx = null;
let stableCount = 0;
let lastAcceptedIdx = null;
let lastAcceptedAt = 0;

/* BLE constants */
const UART_SERVICE_UUID = '6e400001-b5a3-f393-e0a9-e50e24dcca9e';
const UART_NOTIFY_CHAR_UUID = '6e400002-b5a3-f393-e0a9-e50e24dcca9e';
const UART_WRITE_CHAR_UUID  = '6e400003-b5a3-f393-e0a9-e50e24dcca9e';

let bleDevice = null;
let bleServer = null;
let uartService = null;
let notifyChar = null;
let writeChar = null;
const encoder = new TextEncoder();
let writeQueue = Promise.resolve();
let connected = false;
let reconnectAttempts = 0;
const MAX_RECONNECT_ATTEMPTS = 8;

function setStatus(txt, color = '#9fdfff'){
  statusEl.textContent = txt;
  statusEl.style.color = color;
}
function queueGattOperation(op){ writeQueue = writeQueue.then(op, op); return writeQueue; }
function safeLog(...args){ console.log('[BLE]', ...args); }

threshRange.addEventListener('input', ()=>{ threshPct.textContent = threshRange.value + '%'; });
loadBtn.addEventListener('click', loadModel);
connectBtn.addEventListener('click', connectMicrobit);

/* normalize model base helper */
function normalizeBase(urlOrId){
  if(!urlOrId) return null;
  const s = urlOrId.trim();
  if(!s) return null;
  if(s.startsWith('http')){
    try{
      const u = new URL(s);
      const parts = u.pathname.split('/').filter(Boolean);
      const idx = parts.indexOf('models');
      if(idx>=0 && parts.length>idx+1) return `https://teachablemachine.withgoogle.com/models/${parts[idx+1]}/`;
    }catch(e){}
    if(s.endsWith('model.json')) return s.replace(/model\.json$/,'');
    return s.endsWith('/') ? s : s + '/';
  } else {
    return `https://teachablemachine.withgoogle.com/models/${s}/`;
  }
}

/* load model, detect labels and input size */
async function loadModel(){
  const base = normalizeBase(modelUrlInput.value);
  if(!base){ setStatus('Provide model URL or id', '#ffcc66'); return; }
  setStatus('Loading model...');
  try {
    const modelURL = base + 'model.json';
    const metaURL = base + 'metadata.json';
    model = await tf.loadLayersModel(modelURL);

    // Try to fetch metadata.json to get labels and image size
    try {
      const r = await fetch(metaURL); const meta = await r.json();
      if(Array.isArray(meta.labels)) labels = meta.labels.map(l => typeof l === 'string' ? l : (l.name || l));
      else if(Array.isArray(meta.class_names)) labels = meta.class_names;
      else if(Array.isArray(meta['labels'])) labels = meta['labels'];
      if(meta['input_shape'] && Array.isArray(meta['input_shape'])){
        if(meta.input_shape.length >= 3){
          inputHeight = meta.input_shape[1] || inputHeight;
          inputWidth = meta.input_shape[2] || inputWidth;
        }
      } else if(meta['image_size'] && Array.isArray(meta['image_size'])){
        inputHeight = meta.image_size[0] || inputHeight;
        inputWidth = meta.image_size[1] || inputWidth;
      }
    } catch(e){
      // ignore metadata fetch errors
    }

    // fallback: infer from model input if possible
    const inShape = model.inputs?.[0]?.shape;
    if(inShape && inShape.length>=4){
      inputHeight = inShape[1] || inputHeight;
      inputWidth = inShape[2] || inputWidth;
    }

    if(!labels.length){
      const outShape = model.outputs?.[0]?.shape;
      const outLen = outShape ? outShape[outShape.length-1] : 3;
      labels = new Array(outLen).fill(0).map((_,i)=>`Class ${i}`);
    }

    setStatus('Model loaded — ' + labels.length + ' classes', '#00ff99');
    renderClassesPlaceholder();

    // If camera running, start prediction (auto-detect will run inside)
    if(stream && !running) predictLoop();
  } catch(err){
    console.error(err);
    setStatus('Model load failed — check URL/CORS', '#ff6b6b');
    model = null;
  }
}

/* start camera */
async function startCamera(){
  if(stream){ setStatus('Camera already running'); return; }
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
    video.srcObject = stream;
    await video.play();
    setStatus('Camera started', '#9fdfff');
    if(model && !running) predictLoop();
  } catch(err){
    console.error('Camera error', err);
    setStatus(err.name === 'NotAllowedError' ? 'Camera permission denied' : 'Camera error: ' + (err.message || err.name), '#ff6b6b');
  }
}

function renderClassesPlaceholder(){
  classesEl.innerHTML = '';
  labels.forEach((l,i)=>{
    const row = document.createElement('div');
    row.className = 'class-row';
    row.innerHTML = `<div class="class-name">${l}</div><div class="class-pct" id="p-${i}">—</div>`;
    classesEl.appendChild(row);
  });
  classCountEl.textContent = labels.length ? labels.length + ' total' : '—';
}

/* BLE functions unchanged */
async function connectMicrobit(){
  try {
    setStatus('Requesting micro:bit...', '#00c3ff');
    bleDevice = await navigator.bluetooth.requestDevice({
      filters: [{ namePrefix: 'BBC micro:bit' }],
      optionalServices: [UART_SERVICE_UUID]
    });
    if(!bleDevice) throw new Error('No device selected');
    bleDevice.addEventListener('gattserverdisconnected', handleDisconnected);
    deviceNameEl.textContent = `Device: ${bleDevice.name || 'micro:bit'}`;

    setStatus('Connecting...', '#00c3ff');
    bleServer = await bleDevice.gatt.connect();

    setStatus('Getting UART service...', '#00c3ff');
    uartService = await bleServer.getPrimaryService(UART_SERVICE_UUID);

    setStatus('Getting characteristics...', '#00c3ff');
    writeChar = await uartService.getCharacteristic(UART_WRITE_CHAR_UUID).catch(()=>null);
    notifyChar = await uartService.getCharacteristic(UART_NOTIFY_CHAR_UUID).catch(()=>null);
    if(notifyChar && (notifyChar.properties.notify || notifyChar.properties.indicate)){
      await notifyChar.startNotifications();
      notifyChar.addEventListener('characteristicvaluechanged', onNotify);
    }

    connected = true;
    reconnectAttempts = 0;
    setStatus(`Connected: ${bleDevice.name || 'micro:bit'}`, '#00ff99');
    connectBtn.textContent = 'Connected';
    deviceNameEl.textContent = `Device: ${bleDevice.name || 'micro:bit'}`;
  } catch (err) {
    console.error('Connect failed', err);
    setStatus('Bluetooth connection failed (try again)', '#ff6b6b');
    deviceNameEl.textContent = '';
    bleDevice = null;
    connected = false;
    connectBtn.textContent = 'connect micro:bit';
  }
}
function handleDisconnected(event){
  const dev = event.target;
  safeLog(`Device ${dev.name} disconnected`);
  connected = false;
  setStatus('Disconnected — attempting reconnect...', 'orange');
  attemptReconnect();
}
function attemptReconnect(){
  if(!bleDevice){ setStatus('Not connected', '#ffcc66'); connectBtn.textContent = 'connect micro:bit'; return; }
  reconnectAttempts++;
  if(reconnectAttempts > MAX_RECONNECT_ATTEMPTS){
    setStatus('Reconnect failed — click Connect', '#ff6b6b');
    connectBtn.textContent = 'connect micro:bit';
    deviceNameEl.textContent = '';
    return;
  }
  const backoffMs = Math.min(1000 * Math.pow(2, reconnectAttempts-1), 20000);
  safeLog('Reconnect attempt', reconnectAttempts, 'next in ms', backoffMs);
  setTimeout(async () => {
    try {
      setStatus(`Reconnect attempt ${reconnectAttempts}...`, '#00c3ff');
      bleServer = await bleDevice.gatt.connect();
      uartService = await bleServer.getPrimaryService(UART_SERVICE_UUID);
      writeChar = await uartService.getCharacteristic(UART_WRITE_CHAR_UUID).catch(()=>null);
      notifyChar = await uartService.getCharacteristic(UART_NOTIFY_CHAR_UUID).catch(()=>null);
      if(notifyChar && (notifyChar.properties.notify || notifyChar.properties.indicate)){
        await notifyChar.startNotifications();
        notifyChar.addEventListener('characteristicvaluechanged', onNotify);
      }
      connected = true;
      reconnectAttempts = 0;
      setStatus(`Reconnected: ${bleDevice.name || 'micro:bit'}`, '#00ff99');
      connectBtn.textContent = 'Connected';
      deviceNameEl.textContent = `Device: ${bleDevice.name || 'micro:bit'}`;
    } catch(e){
      console.warn('Reconnect attempt failed', e);
      attemptReconnect();
    }
  }, backoffMs);
}
function onNotify(ev){
  const value = ev.target.value;
  const text = new TextDecoder().decode(value);
  safeLog('Notified:', text);
}
function sendUARTRaw(bytes){
  if(!writeChar){
    safeLog('No write characteristic - cannot send');
    setStatus('Not writable - reconnect or check micro:bit firmware', '#ff6b6b');
    return Promise.reject(new Error('No write characteristic'));
  }
  return queueGattOperation(async () => {
    try {
      if(typeof writeChar.writeValue === 'function'){
        await writeChar.writeValue(bytes);
      } else if(typeof writeChar.writeValueWithoutResponse === 'function'){
        await writeChar.writeValueWithoutResponse(bytes);
      } else {
        if(writeChar.properties && writeChar.properties.writeWithoutResponse && typeof writeChar.writeValue === 'function'){
          await writeChar.writeValue(bytes);
        } else {
          throw new Error('No writable method on characteristic');
        }
      }
      safeLog('Sent bytes', bytes);
    } catch (err){
      console.error('Write failed', err);
      throw err;
    }
  });
}
async function sendToMicrobit(text){
  if(!connected || !writeChar){
    safeLog('Skipped send - not connected or writable');
    return;
  }
  try {
    const payload = encoder.encode(String(text) + '\n');
    await sendUARTRaw(payload);
  } catch(e){
    console.error('sendToMicrobit error', e);
  }
}
function renderProbabilities(data){
  data.forEach((p,i)=>{
    const el = document.getElementById('p-'+i);
    if(el) el.textContent = (p*100).toFixed(0) + '%';
  });
}

/* Utility: compute probabilities for the current offscreen canvas using a normalization mode.
   Returns a Float32Array of probabilities. Ensures tidy is synchronous and disposes tensors properly.
   normMode: 'minus1to1' or 'zero1'
*/
async function computeProbsFromCanvas(offCanvas, normMode){
  // produce tensor of model output inside tidy synchronously and return a clone of logits/probs tensor
  const predTensor = tf.tidy(()=> {
    let img = tf.browser.fromPixels(offCanvas);
    if(img.shape[2] === 4) img = img.slice([0,0,0],[img.shape[0],img.shape[1],3]);
    if(img.shape[0] !== inputHeight || img.shape[1] !== inputWidth){
      img = tf.image.resizeBilinear(img, [inputHeight, inputWidth], true);
    }
    if(normMode === 'minus1to1'){
      img = img.toFloat().div(127.5).sub(1);
    } else {
      img = img.toFloat().div(255.0);
    }
    const bat = img.expandDims(0);
    const out = model.predict(bat);
    // return a cloned tensor so tidy doesn't dispose the returned tensor
    if(Array.isArray(out)) return out[0].clone();
    return out.clone();
  });

  // now get numeric array and dispose the tensor
  const raw = await predTensor.data();
  predTensor.dispose();
  let arr = Array.from(raw);
  const sum = arr.reduce((a,b)=>a+b,0);
  if(!(sum > 0.9 && sum < 1.1)){
    // apply softmax (safe to use tidy)
    const soft = tf.tidy(()=> tf.softmax(tf.tensor(arr)));
    const softData = await soft.data();
    soft.dispose();
    arr = Array.from(softData);
  }
  return arr;
}

/* Auto-detect normalization (tries two modes on a short warm-up of frames and picks which gives higher avg max-prob).
   Also chooses a smoothing frame count automatically.
*/
async function autoDetectSettings(offCanvas, sampleFrames = 6){
  setStatus('Auto-detecting model input (warming up)...', '#00c3ff');
  // try minus1..1 and 0..1, compute average peak confidence
  const modes = ['minus1to1','zero1'];
  const totals = { minus1to1:0, zero1:0 };
  for(let f=0; f<sampleFrames; f++){
    // draw current video frame into offCanvas (mirror)
    const ctx = offCanvas.getContext('2d');
    ctx.save();
    ctx.translate(offCanvas.width,0);
    ctx.scale(-1,1);
    ctx.drawImage(video,0,0,offCanvas.width,offCanvas.height);
    ctx.restore();
    for(const m of modes){
      try {
        const probs = await computeProbsFromCanvas(offCanvas, m);
        const peak = Math.max(...probs);
        totals[m] += peak;
      } catch(e){
        console.warn('Auto detect compute error', e);
      }
    }
    await new Promise(r=>setTimeout(r, 60)); // small delay to capture slightly different frames
  }
  const avgMinus = totals['minus1to1'] / sampleFrames;
  const avgZero = totals['zero1'] / sampleFrames;
  const chosen = avgMinus >= avgZero ? 'minus1to1' : 'zero1';
  // smoothing heuristic: if chosen peak is noisy pick higher smoothing; else lower smoothing
  const chosenAvgPeak = chosen === 'minus1to1' ? avgMinus : avgZero;
  // peak near 0.9 -> confident, use low smoothing; if low peak use higher smoothing
  let smoothingFrames = 5;
  if(chosenAvgPeak < 0.45) smoothingFrames = 8;
  else if(chosenAvgPeak < 0.65) smoothingFrames = 6;
  else smoothingFrames = 4;
  setStatus(`Auto-detect done — normalization: ${chosen === 'minus1to1' ? '-1→1' : '0→1'}, smoothing: ${smoothingFrames}`, '#00ff99');
  return { norm: chosen, smoothingFrames };
}

/* Main predict loop (uses computeProbsFromCanvas; smoothing buffer averaging; stable-frame decision)
   This loop no longer uses async function inside tf.tidy so the tidy error is resolved.
*/
async function predictLoop(){
  if(!model){ setStatus('Load model first', '#ffcc66'); return; }
  if(!stream){ setStatus('Start camera first', '#ffcc66'); return; }
  running = true;
  setStatus('Warming up and auto-configuring...', '#9fdfff');

  // offscreen canvas sized to model input
  const off = document.createElement('canvas');
  off.width = inputWidth; off.height = inputHeight;
  const ctx = off.getContext('2d');

  // run auto-detect (samples some frames)
  const settings = await autoDetectSettings(off, 6);
  const normMode = settings.norm;
  let smoothingFrames = settings.smoothingFrames;

  // smoothing buffer
  const smoothingBuffer = [];

  setStatus('Predicting...', '#9fdfff');

  async function step(){
    if(!running) return;
    try {
      // draw mirrored frame into off (we will pass off to computeProbsFromCanvas)
      ctx.save();
      ctx.translate(off.width, 0);
      ctx.scale(-1, 1);
      ctx.drawImage(video, 0, 0, off.width, off.height);
      ctx.restore();

      // get probs for this frame using chosen normMode
      const data = await computeProbsFromCanvas(off, normMode);

      // add to smoothing buffer and compute average
      smoothingBuffer.push(data);
      if(smoothingBuffer.length > smoothingFrames) smoothingBuffer.shift();
      const avg = new Array(data.length).fill(0);
      smoothingBuffer.forEach(arr=>{
        for(let i=0;i<arr.length;i++) avg[i]+=arr[i];
      });
      for(let i=0;i<avg.length;i++) avg[i] = avg[i] / smoothingBuffer.length;

      if(labels.length) renderProbabilities(avg);

      // decision logic
      const confThreshold = Math.max(0, Math.min(1, (parseInt(threshRange.value)||65)/100));
      let bestIdx = 0; let bestProb = avg[0]||0;
      for(let i=1;i<avg.length;i++){ if(avg[i]>bestProb){ bestProb=avg[i]; bestIdx=i; } }

      const now = Date.now();
      if(lastAcceptedAt && (now - lastAcceptedAt) < COOLDOWN_MS){
        if(lastAcceptedIdx !== null){
          mainLabelEl.textContent = `${labels[lastAcceptedIdx] || ('Class '+lastAcceptedIdx)}`;
        }
      } else {
        if(bestProb >= confThreshold){
          if(candidateIdx === bestIdx) stableCount++;
          else { candidateIdx = bestIdx; stableCount = 1; }
          if(stableCount >= STABLE_FRAMES_REQUIRED){
            if(lastAcceptedIdx !== candidateIdx){
              lastAcceptedIdx = candidateIdx;
              lastAcceptedAt = Date.now();
              mainLabelEl.textContent = `${labels[lastAcceptedIdx] || ('Class '+lastAcceptedIdx)}`;
              try { sendToMicrobit(labels[lastAcceptedIdx]); } catch(e){ console.error(e); }
            }
          }
        } else {
          // reset candidate if below threshold (helps avoid drift)
          candidateIdx = null;
          stableCount = 0;
        }
      }

    } catch(err){
      console.error('Prediction loop error', err);
      setStatus('Prediction error — see console', '#ff6b6b');
      running = false;
      return;
    }
    requestAnimationFrame(step);
  }
  step();
}

/* cleanup on unload */
window.addEventListener('beforeunload', ()=>{
  try { if(stream) stream.getTracks().forEach(t=>t.stop()); } catch(e){}
  try { if(notifyChar && notifyChar.stopNotifications) notifyChar.stopNotifications(); } catch(e){}
  try { if(bleDevice && bleDevice.gatt && bleDevice.gatt.connected) bleDevice.gatt.disconnect(); } catch(e){}
});

/* initial messages and autostart camera */
setStatus('Ready — paste model URL, Load Model. Camera will start automatically.');
threshPct.textContent = threshRange.value + '%';

(async function autoStart(){
  try {
    await startCamera();
  } catch(e){
    // camera errors already handled
  }
})();
</script>
</body>
</html>
